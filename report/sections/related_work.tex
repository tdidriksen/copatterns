%!TEX root = ../main.tex
\section{Related Work}
\label{sec:related_work}
This section gives a survey of relevant literature, mostly covering approaches to ensuring termination or productivity of programs defined over both inductive and coinductive data.

\subsection{Size-change Termination}
Due to the fact that Idris already has a working totality checker using size-change termination\,\citep{BradyIdrisImpl13}, it would be interesting if the size-change principle could be used for determining the productivity of corecursive functions as well. The size-change principle for termination was first proposed for a strict first-order functional language (without loop constructs) by Lee, Jones, and Ben-Amram\,\citep{LeeJones01SizeChange}. The principle essentially states that if infinitely many recursive calls to a function would lead to infinite decrease in some parameter value, then the function must be terminating, since any value of an inductive type must have finite size. This last condition is of particular importance, as the size-change principle cannot in general recognize functions as being terminating if they have parameters that do not exhibit a well-founded order. Lee, Jones, and Ben-Amram present two realizations of the principle, one using automata and one using a call graph. In the graph formulation, termination is determined by identifying any recursive calls (both direct and indirect) through cycles in the call graph, and then constructing a ``size-change graph'' for each of these. The size-change graphs are then used to find out whether infinite descent in some parameter value is present. One of the limitations of this approach is that parameter values must decrease monotonically: Values cannot at any point become structurally larger, even though the total change in size in a call chain would ultimately lead a to a decreasing value. Two examples of size-change terminating functions are shown in Figure~\ref{fig:sizechange_plus_map}. In both examples, the recursive call happens on structurally smaller input.

\begin{figure}
\begin{alltt}
plus : Nat -> Nat -> Nat           map : (a -> b) -> Vect n a -> Vect n b 
plus Z      m = m                  map f []        = []
plus (S n') m = plus n' m          map f (x :: xs) = f x :: map f xs 
\end{alltt}
\caption{Two size-change terminating functions.}
\label{fig:sizechange_plus_map}
\end{figure}

Since its first-order formulation, the principle has been proven to work for more expressive cases. Jones and Bohr\,\citep{Jones04Untyped} showed that size-change termination can be applied to the untyped lambda calculus using abstract interpretation. Interesting results of this work include size-change termination of programs employing the Y-combinator.

Following the work on the untyped lambda calculus, Sereni and Jones generalized the size-change principle to handle a higher-order functional language with user-defined data types and general recursion\,\citep{Sereni05terminationanalysis,Sereni06Phd}. Here, a termination criterion is presented which works for arbitrary control-flow graphs, and in turn is able to give an approximation of termination for both strict and lazy functional programs. A key point in this work is how different approaches to control-flow and call graph construction may influence the preciseness of the termination analysis.

Most implementations of the size-change principle only work on data for which some well-founded order exists. Nevertheless, Avery\,\citep{Avery06} presented a formulation in which it is possible to detect size-change termination for non-well-founded data types --- in particular, this formulation is shown to work for a language with an integer type. Instead of identifying infinite descent using a well-founded partial order on parameters, the analysis is based on a decrease in invariants which are found to hold for each program point. These invariants are inferred automatically from the structure of the program. The idea is that if the value of some invariant (which can involve arbitrarily many values) can be shown to decrease on every passage of a program point, then the program terminates. A simple example of a size-change terminating program in Avery's implementation is given in Figure~\ref{fig:avery_example}. The invariant for the inner loop is \texttt{n - j + i}, while the one for the outer loop is \texttt{n - i}. These cannot decrease forever, and therefore the program is size-change terminating. 

\begin{figure}
\begin{alltt}
for (i = 0; i <= n; i++) \{
  for (j = 0; j-i <= n; j++);
\}
return;
\end{alltt}
\caption{A size-change terminating program with integers, written in a subset of C.}
\label{fig:avery_example}
\end{figure}

Avery's formulation is insufficient or impractical for productivity checking definitions with copatterns in several aspects. First, it is still assumed that totality is determined solely on the basis of an infinitely decreasing property that is bounded from below. However, many corecursive functions exhibit no such property; Indeed, one of the virtues of such functions is exactly the ability to define infinite structures. Secondly, the formulation works on a graph of program points. Since it is valid for a corecursive function to be defined in terms of itself, non-termination for copatterns only becomes apparent when observations are defined in terms of themselves. Constructing a graph of all observations in the system would be necessary for this approach to work, and such an undertaking might not be ideal, since it would require all observations to be unfolded (see Section \ref{sec:productivity}).

In more recent work, Hyvernat\,\citep{Hyvernat13} has proposed a formulation of the size-change principle for functional languages which to a certain degree solves the problem of non-monotonic decrease in parameter values. The motivation behind this work is to incorporate size-change termination into the PML language\,\cite{PMLLanguage}. Non-monotonic decrease is detected by tracking the size of a parameter throughout the entire control-flow graph, instead of merely recording whether each call in isolation leads to a decrease in some value. As an extension, Hyvernat proposes that infinite data can be covered by the principle by counting the number of (lambda) abstractions and compare these to the number of function applications in a program. His idea is that if we do not reduce under abstractions, then if a function has more abstractions than applications, then it will be productive. In this form, however, this proposal seems inadequate for a usable productivity checker for copatterns.

The termination criterion that comes closest to the size-change principle, and which actually predates the original size-change article (\citep{LeeJones01SizeChange}), is the one developed for the \texttt{foetus} termination checker by Abel\,\citep{Abel98foetus}. This criterion forms the basis of the totality checker used by Agda\,\citep{Norell:thesis}. In a similar manner, Abel identifies recursive calls in a call graph and determines termination by tracking changes in parameter sizes. This work does not make any mention of productivity for coinductive data, however.

It seems that there exists no current formulation of the size-change principle which describes how productivity for coinductive data can be ensured in a way that is suitable for a system with copatterns. In the following, we will explore several different approaches to productivity, unrelated to the size-change principle.

\subsection{Guarded Corecursion}
Because of the duality between inductive and coinductive types, it may be compelling to think that if size-change termination for inductive types works by identifying structurally smaller values, then a dual notion of ``size-change productivity'' would exist that worked by identifying structurally larger values. The idea of \emph{guarded corecursion} uses exactly this idea to determine productivity: Where values become structurally smaller as the result of pattern matching, they become structurally larger by constructor application. Therefore, the \emph{guardedness principle} states that a coinductive definition is guarded if all corecursive calls appear directly under a coinductive constructor. This has the implication that the productivity of corecursive functions can be detected by a purely syntactic check. 

The guardedness principle was first proposed by Coquand\,\citep{Coquand94} as an important part of a ``guarded proof induction principle'' for a proof system containing coinductive definitions, inspired by a similar approach in the area of process calculi by Milner\,\citep{Milner82}. In continuation of Coquand's efforts, Gim\'{e}nez applied the method to the Calculus of Constructions in order to avoid the introduction of non-normalizable terms\,\citep{Gimenez95}. 

The guardedness property described by Coquand and Gim\'{e}nez was intended to be used within a proof system (e.g. Coq\,\citep{Coq:manual}) in order to have proofs involving coinductive types, not necessarily taking a more practical programming setting into account. In a programming setting, Telford and Turner argue that this approach is too conservative\,\citep{Telford98ensuringthe}. Because \emph{all} corecursive calls to a function must appear directly under a constructor, many intuitive defintions of standard functions (e.g. \texttt{nats} in Figure \ref{fig:nats}) are not considered productive.

In their \emph{Elementary Strong Functional Programming} (ESFP) system\,\citep{Telford97ensuringstreams,Telford98ensuringthe}, Telford and Turner extend the principle to accept a wider range of corecursive functions as being productive, showing it to be usable in a realistic programming setting. They achieve this by considering guardedness more abstractly over a domain of guardedness levels, such that productive corecursion is bounded by a given ``depth''. As an advanced example, they show that the Hamming function is considered productive within their system.

Another approach to coping with the conservative nature of the original guardedness principle is to consider alternative programming styles, making productive definitions easier to write. Following the incorporation of the guardedness condition into the Agda totality checker\,\citep{AltenkirchNAD10}, Danielsson\,\citep{Danielsson10beatingthe} described a method for working around the guardedness condition whenever it rejects a productive program. For each situation, he designs an embedded domain specific language, implements the rejected program in said language, and then provides an interpreter which is accepted by the guardedness condition. None of these steps happen automatically, but must be done manually. Although useful, Danielsson argues that efficiency is a concern, and that the best solution might be to entirely move away from using guardedness for productivity. Sized types have since been implemented in Agda.


\subsection{Sized Types}
\label{sec:sized_types}
The idea of sized types is that instead of detecting totality using a syntactic check, such as it is the case for guarded corecursion, size information is added to the type system. Because the type system can then provide guarantees about the sizes of both the input and output of a function, this enables the user to write stronger type specifications. The term ``size'' is used quite broadly here, without implying any specific structure of the data. Unlike the size-change principle or guarded corecursion, approaches using sized types for totality checking of both inductive and coinductive data within the same system have been presented\,\citep{Abel13Wellfounded}. An Agda example of a coinductive stream type with sized types is shown in Figure~\ref{fig:agda_stream_sized_types}. Here, the \texttt{tail} observation has an implicit size parameter \texttt{j}, the type of which (\texttt{Size< i}) indicates that the result of a \texttt{tail} observation is a smaller \texttt{Stream} than the observed \texttt{Stream}, which has size \texttt{i}. This definition of streams can be used to define the natural numbers using sized types, as shown in Figure~\ref{fig:agda_nats_sized_types}. The productivity of the \texttt{nats} and \texttt{map} functions can be established by enforcing that the outcome of an observation has a smaller size than the observed stream. This is apparent from the size arguments applied to \texttt{map} in both functions, since \texttt{j} is less than \texttt{i} by definition. Note that all of these size annotations must be provided by the user.

\begin{figure}
\begin{alltt}
record Stream \{i : Size\} (A : Set) : Set where
  coinductive
  field
    head : A
    tail : \{j : Size< i\} ->  Stream \{j\} A
open Stream
\end{alltt}
\caption{A \texttt{Stream} defined with sized types in Agda.}
\label{fig:agda_stream_sized_types}
\end{figure}

\begin{figure}
\begin{alltt}
map : \{i A B\} (f : A -> B) -> (s : Stream \{i\} A) -> Stream \{i\} B
head (map \{i\} f s)     = f (head s)
tail (map \{i\} f s) \{j\} = map \{j\} f (tail s \{j\})

nats : \{i\} -> Stream \{i\} Nat
head (nats \{i\})     = Z
tail (nats \{i\}) \{j\} = map \{j\} S (nats \{j\})
\end{alltt}
\caption{The corecursive \texttt{nats} function in Agda.}
\label{fig:agda_nats_sized_types}
\end{figure}

Sized types for totality checking were first proposed by Hughes, Pareto, and Sabry\,\citep{Hughes96} for reactive systems, where each data type introduced into a program is associated with a family of sized types indicating the bounds of a value of that type. A similar idea was developed by Amadio and Coupet-Grimal\,\citep{Amadio98}, where guard conditions are introduced into the type system to ensure the productivity of coinductive data, following the work of Coquand\,\citep{Coquand94} and Gim\'{e}nez\,\citep{Gimenez95}.

Eduarde Gim\'{e}nez also presented a system for typing recursive definitions in an extension of the Calculus of Constructions using sized types\,\citep{Gimenez98structuralrecursive}. A notable result of this work is that any well-typed term in the proposed extension is normalizing with respect to lazy evaluation, widening the domain of functions to which type-based termination is applicable substantially. In the wake of this extension, Abel\,\citep{Abel99terminationchecking} wrote a quite accessible paper on using sized types for termination checking of both inductive types, showing that bidirectional type checking\,\citep{Pierce00} is suitable for a system with sized types. In addition, it is described how infinite streams defined by coinductive types can be encoded in a language as functions on natural numbers, and that the productivity of a stream can be understood in terms of its \emph{definedness}, meaning the number of times it can safely be unfolded.

The notion of definedness is also an important part of Abel and Pientka's work on applying sized types to a system with copatterns\,\citep{Abel13Wellfounded}, although here it is defined more precisely as the \emph{depth} of a value of coinductive type. By directly using the notion of depth in the type system, they show that totality of both coinductive definitions with copatterns and inductive definitions (as well as mixed inductive-coinductive) can be determined by well-founded induction on sizes within the type system. The method is shown to work for System F\textsubscript{$\omega$}, and has later been implemented in Agda along with copatterns. Thus, sized types are a candidate for detecting productivity of corecursive functions with copatterns in Idris. However, due to various concerns discussed in Section \ref{sec:productivity}, sized types may not be a desirable solution.

In relation to other methods for totality checking, Thibodeau\,\citep{Thibodeau11} presented an interesting comparison between sized types and termination checking by structural size change (such as the methods used for the size-change principle and the \texttt{foetus} termination checker). Here, Thibodeau concludes that sized types in general should be preferred over approaches examining structure, since they generally are more flexible. The main concern regarding sized types is that size annotations make the code harder to read, and seem unnecessary from the point of view of the user of the language. Thibodeau expects, however, that it would be possible to reconstruct most size annotations automatically in a mature system. To our knowledge, it has yet to be investigated whether all size annotations could potentially be reconstructed, essentially making the user oblivious to the use of sized types.

\subsection{Methods Based On Time}
Atkey and McBride\,\citep{AtkeyMcBride13} have developed an experimental calculus with coinductive types in which productive programs can be typed by introducing ``clock variables'' to the type system. Much like the \texttt{Inf} operator described in Section~\ref{sec:stateinidris}, they use a \emph{guardedness type constructor} to indicate values that will only be available ``tomorrow''. These guarded types are then parameterized by clock variables, which has the effect that the output on a given ``day'' must be produced on that day, i.e. from the data that is available that day. Since Atkey and McBride quantify over clock variables in each definition, these provide only local constraints, expressing the relationship between input and output. This should be contrasted with the nature of sized types, where constraints can be expressed in terms of globally available types. In its current form, the system by Atkey and McBride is not an ideal solution for productivity checking definitions with copatterns, since it seems to require a certain style of programming in order to be usable. Furthermore, it still requires the user to specify ``time annotations'' for all definitions, which is not very different from sized types, although they only have local scope. A system based on local time constraints is quite interesting, however, and will be explored in greater detail as part of our proposal for a productivity algorithm in Section~\ref{sec:productivity}.

%Atkey and McBride\,\citep{AtkeyMcBride13} have developed an experimental calculus with coinductive types in which productive programs can be typed by introducing ``clock variables'' to the type system. The idea is to move the guardedness check from the syntactic level to the type level, by using \emph{guardedness type constructors} to represent values which can only be used in a guarded manner. These type constructors are then annotated by clock variables, such that it is possible for them to model guarded values which may only be available ``tomorrow''. The input and output of a function can then be typed such that they run on the same or related clocks, expressing certain guarantees about how many observations one can make on a given value. This idea of time will be revisited in Section \ref{sec:productivity}\todo{Remember this reference to Section \ref{sec:productivity}}. The difference between the approach taken by Atkey and McBride and full-blown sized types, is that they require fewer size annotation from the user, which is achieved by utilizing the described notion of time. The downside is that it does at this point require a certain style of programming which seems quite inflexible, making the approach less ideal for programming with copatterns.

Krishnaswami\,\citep{Krishnaswami13} devised a language for functional reactive programming based on time. In his system, it is impossible to write a program which gives rise to either ``space leaks'' (non-permanent memory leaks from capturing too much history) or ``time leaks'' (dependence on past values for arbitrary intervals of time). This is achieved by keeping track of a global clock, and then defining two operational semantics for evaluation of programs. One of these define evaluation of an expression at the current time, while the other has a ``tick relation'' which advances the global clock. Whenever the global clock is advanced, all values which can no longer be referenced due to time constraints are discarded from the environment, thus eliminating space leaks. Furthermore, at each clock tick, the values which have become available at that tick are unfolded, in effect making time leaks impossible. The type system is extended with rules that make sure that no references to unavailable data can be made. This work is quite interesting in relation to the solution we propose in Section~\ref{sec:productivity}, since Krishnaswami's approach only allows definitions in terms of future values. To type programs dependent on time, he uses \emph{temporal recursive types}, in which the recursive occurrence is not available before the next clock tick. This is similar to how time measures are used in our proposal, where the next observation on a coinductive instance occurs at the next moment in time. Therefore, temporal recursive types could most likely be used for productivity checking.
