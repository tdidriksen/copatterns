%!TEX root = ../main.tex
\section{Related Work}
\label{sec:related_work}
This section gives a survey of relevant literature, mostly covering approaches to ensuring termination or productivity of programs defined over both inductive and coinductive data.

\subsection{Size-change Termination}
Due to the fact that Idris already has a working totality checker using size-change termination\,\citep{BradyIdrisImpl13}, it is important that a solution for determining the productivity of corecursive functions takes this principle into account. The size-change principle for termination was first proposed for a strict first-order functional language (without loop constructs) by Lee, Jones, and Ben-Amram\,\citep{LeeJones01SizeChange}. The principle essentially states that if infinitely many recursive calls to a function would lead to infinite decrease in some parameter value, then the function must be terminating, since any value of an inductive type must have finite size. This last condition is of particular importance, as the size-change principle cannot in general recognize functions as being terminating if they have parameters that do not exhibit a well-founded order. Lee, Jones, and Ben-Amram present two realizations of the principle, one using automata and one using a call graph. In the graph formulation, termination is determined by identifying any recursive calls (both direct and indirect) through cycles in the call graph, and then constructing a ``size-change graph'' for each of these. The size-change graphs are then used to find out whether infinite descent in some parameter value is present. One of the limitations of this approach is that parameter values must decrease monotonically: Values cannot at any point become structurally larger, even though the total change in size in a call chain would ultimately lead a to a decreasing value.

Since its first-order formulation, the principle has been proven to work for more expressive cases. Jones and Bohr\,\citep{Jones04Untyped} showed that size-change termination can be applied to the untyped lambda calculus using abstract interpretation. Interesting results of this work include size-change termination of programs employing the Y-combinator.

Following the work on the untyped lambda calculus, Sereni and Jones generalized the size-change principle to handle a higher-order functional language with user-defined data types and general recursion\,\citep{Sereni05terminationanalysis,Sereni06Phd}. Here, a termination criterion is presented which works for arbitrary control-flow graphs, and in turn is able to give an approximation of termination for lazy functional programs. A key point in this work is how different approaches to control-flow and call graph construction may influence the preciseness of the termination analysis.

Most implementations of the size-change principle only work on data for which some well-founded order exists. Nevertheless, Avery\,\citep{Avery06} presented a formulation in which it is possible to detect size-change termination for non-well-founded data types --- in particular, this formulation is shown to work for a language with an integer type. Instead of identifying infinite descent using a well-founded partial order on parameters, the analysis is based on a decrease in invariants which are found to hold for each program point. These invariants are inferred automatically from the structure of the program. The idea is that if the value of some invariant (which can involve arbitrarily many values) can be shown to decrease on every passage of a program point, then the program terminates. While an approach to size-change termination involving non-well-founded data is closer to a usable productivity algorithm for corecursive functions with copatterns, Avery's formulation is insufficient or impractical in several aspects. First, it is still assumed that totality is determined solely on the basis of an infinitely decreasing property that is bounded from below. However, many corecursive functions exhibit no such property; Indeed, one of the virtues of such functions is exactly the ability to define infinite structures. Secondly, the formulation works on a graph of program points. Since it is valid for a corecursive function to be defined in terms of itself, non-termination for copatterns only becomes apparent when observations are defined in terms of themselves. Constructing a graph of all observations in the system would be necessary for this approach to work, and such an undertaking might not be ideal, since it would require all observations to be unfolded (see Section \ref{sec:productivity}).

In more recent work, Hyvernat\,\citep{Hyvernat13} has proposed a formulation of the size-change principle for functional languages which to a certain degree solves the problem of non-monotonic decrease in parameter values. The motivation behind this work is to incorporate size-change termination into the PML language\,\cite{PMLLanguage}. Non-monotonic decrease is detected by tracking the size of a parameter throughout the entire control-flow graph, instead of merely recording whether each call in isolation leads to a decrease in some value. As an extension, Hyvernat proposes that infinite data can be covered by the principle by counting the number of (lambda) abstractions and compare these to the number of function applications in a program. In this form, however, this proposal seems inadequate for a usable productivity checker for copatterns, since it relies directly on function abstractions.

The termination criterion that comes closest to the size-change principle, and which actually predates the original size-change article (\citep{LeeJones01SizeChange}), is the one developed for the \texttt{foetus} termination checker by Abel\,\citep{Abel98foetus}. This criterion forms the basis of the totality checker used by Agda\,\citep{Norell:thesis}. In a similar manner, Abel identifies recursive calls in a call graph and determines termination by tracking changes in parameter sizes. This work does not make any mention of productivity for coinductive data, however.

It seems that there exists no current formulation of the size-change principle which describes how productivity for coinductive data can be ensured in a way that is suitable for a system with copatterns. In the following, we will explore several different approaches to productivity, unrelated to the size-change principle.

\subsection{Guarded Corecursion}
The basic idea of guarded corecursion is that the productivity of corecursive functions can be ensured by a purely syntactic check. It was first proposed by Coquand\,\citep{Coquand94} as an important part of a ``guarded proof induction principle'' for a proof system containing coinductive definitions, inspired by a similar approach in the area of process calculi by Milner\,\citep{Milner82}. In continuation of Coquand's efforts, Gim\'{e}nez applied the method to the Calculus of Constructions in order to avoid the introduction of non-normalizable terms\,\citep{Gimenez95}. 

The guardedness property described by Coquand and Gim\'{e}nez was intended to be used within a proof system (e.g. Coq\,\citep{Coq:manual}) in order to prove specifications involving coinductive types, not necessarily taking a more practical programming setting into account. In such setting, Telford and Turner argue that this approach is too conservative\,\citep{Telford98ensuringthe}. Because \emph{all} corecursive calls to a function must appear directly under a constructor, many intuitive defintions of standard functions (e.g. \texttt{nats} in Figure \ref{fig:nats}) are not considered productive.

In their \emph{Elementary Strong Functional Programming} (ESFP) system\,\citep{Telford97ensuringstreams,Telford98ensuringthe}, Telford and Turner extend the principle to accept a wider range of corecursive functions as being productive, showing it to be usable in a realistic programming setting. They achieve this by considering guardedness more abstractly over a domain of guardedness levels, such that productive corecursion is bounded by a given ``depth''. As an advanced example, they show that the Hamming function is considered productive within their system. A variant of this idea will be discussed in relation to copatterns in Section \ref{sec:productivity}\todo{Remember this forward reference to Section \ref{sec:productivity}}.

Another approach to coping with the conservative nature of the original guardedness principle is to consider alternative programming styles, making productive definitions easier to write. Following the incorporation of the guardedness condition into the Agda totality checker\,\citep{AltenkirchNAD10}, Danielsson\,\citep{Danielsson10beatingthe} described a method for working around the guardedness condition whenever it rejects a productive program. For each situation, he designs an embedded domain specific language, implements the rejected program in said language, and then provides an interpreter which is accepted by the guardedness condition. None of these steps happen automatically, but must be done manually. Although useful, Danielsson argues that efficiency is a concern, and that the best solution might be to entirely move away from using guardedness for productivity. For Agda, sized types have since been implemented.


\subsection{Sized Types}
\label{sec:sized_types}
The idea of sized types is that instead of detecting totality using a syntactic check, such as it is the case for guarded corecursion, size information is added to the type system. Because the type system can then provide guarantees about the sizes of both the input and output of a function, this enables the user to write stronger type specifications. The term ``size'' is used quite broadly here, without implying any specific structure of the data. Unlike the size-change principle or guarded corecursion, approaches using sized types for totality checking of both inductive and coinductive data within the same system have been presented\,\citep{Abel13Wellfounded}.

Sized types for totality checking were first proposed by Hughes, Pareto, and Sabry\,\citep{Hughes96} for reactive systems, where each data type introduced into a program is associated with a family of sized types indicating their bounds. A similar idea was developed by Amadio and Coupet-Grimal\,\citep{Amadio98}, where guard conditions are introduced into the type system to ensure the productivity of coinductive data, following the work of Coquand\,\citep{Coquand94} and Gim\'{e}nez\,\citep{Gimenez95}.

Eduarde Gim\'{e}nez also presented a system for typing recursive definitions in an extension of the Calculus of Constructions using sized types\,\citep{Gimenez98structuralrecursive}. A notable result of this work is that any well-typed term in the proposed extension is normalizing with respect to lazy evalution, widening the domain of functions to which type-based termination is applicable substantially. In the wake of this extension, Abel\,\citep{Abel99terminationchecking} wrote a quite accessible paper on using sized types for termination checking of both inductive types, showing that bidirectional type checking\,\citep{Pierce00} is suitable for a system with sized types. In addition, it is described how infinite streams defined by coinductive types can be encoded in a language as functions on natural numbers, and that the productivity of a stream can be understood in terms of its \emph{definedness}, meaning the number of times it can safely be unfolded.

The notion of definedness is also an important part of Abel and Pientka's work on applying sized types to a system with copatterns\,\citep{Abel13Wellfounded}, although here it is defined more precisely as the \emph{depth} of a value of coinductive type. By directly using the notion of depth in the type system, they show that totality of both coinductive definitions with copatterns and inductive definitions (as well as mixed inductive-coinductive) can be determined by well-founded induction on sizes within the type system. The method is shown to work for System F\textsubscript{$\omega$}, and has later been implemented in Agda along with copatterns. As such, sized types are a candidate for detecting productivity of cofunctions with copatterns in Idris. However, due to various concerns discussed in Section \ref{sec:productivity}\todo{Remember this forward reference to Section \ref{sec:productivity}}, sized types may not be a desirable solution.

In relation to other methods for totality checking, Thibodeau\,\citep{Thibodeau11} presented an interesting comparison between sized types and termination checking by structural size change (such as the methods used for the size-change principle and the \texttt{foetus} termination checker). Here, Thibodeau concludes that sized types in general should be preferred over approaches examining structure, since they generally are more flexible. The main concern regarding sized types is that size annotations make the code harder to read, and seems unnecessary from the point of view of the user. Thibodeau expects, however, that it would be possible to reconstruct most size annotations automatically in a mature system. To our knowledge, it has yet to be investigated whether all size annotations could potentially be reconstructed, essentially making the user oblivious to the use of sized types.

\subsection{Methods Based On Time}
Atkey and McBride\,\citep{AtkeyMcBride13} have developed an experimental calculus with coinductive types in which productive programs can be typed by introducing ``clock variables'' to the type system. Much like the \texttt{Inf} operator described in Section~\ref{sec:stateinidris}, they use a \emph{guardedness type constructor} to indicate values that will only be available ``tomorrow''. These guarded types are then parameterized by clock variables, which has the effect that the output on a given ``day'' must be produced on that day, i.e. from the data that is available that day. Since Atkey and McBride quantify over clock variables in each definition, these provide only local constraints, expressing the relationship between input and output. This should be contrasted with the nature of sized types, where constraints can be expressed in terms of globally available types. In its current form, the system by Atkey and McBride is not an ideal solution for productivity checking definitions with copatterns, since it seems to require a certain style of programming in order to be usable. Furthermore, it still requires the user to specify ``time annotations'' for all definitions, which is not very different from sized types, although they only have local scope. A system based on local time constraints is quite interesting, however, and will be explored in greater detail as part of our proposal for a productivity algorithm in Section~\ref{sec:productivity}.

%Atkey and McBride\,\citep{AtkeyMcBride13} have developed an experimental calculus with coinductive types in which productive programs can be typed by introducing ``clock variables'' to the type system. The idea is to move the guardedness check from the syntactic level to the type level, by using \emph{guardedness type constructors} to represent values which can only be used in a guarded manner. These type constructors are then annotated by clock variables, such that it is possible for them to model guarded values which may only be available ``tomorrow''. The input and output of a function can then be typed such that they run on the same or related clocks, expressing certain guarantees about how many observations one can make on a given value. This idea of time will be revisited in Section \ref{sec:productivity}\todo{Remember this reference to Section \ref{sec:productivity}}. The difference between the approach taken by Atkey and McBride and full-blown sized types, is that they require fewer size annotation from the user, which is achieved by utilizing the described notion of time. The downside is that it does at this point require a certain style of programming which seems quite inflexible, making the approach less ideal for programming with copatterns.

Krishnaswami\,\citep{Krishnaswami13} devised a language for functional reactice programming based on time. In his system, it is impossible to write a program that references data which is not known to be well-typed at the current time. This is achieved by keeping track of a global clock, and then defining two operational semantics for evaluation of programs. One of these define evaluation of an expression at the current time, while the other has a ``tick relation'' which advances the global clock. Whenever the global clock is advanced, all values which can no longer be referenced due to time constraints are discarded from the environment. In effect, it becomes impossible to reference data which ``leak time'', i.e. should not currently be available according to the clock. The type system is extended with rules that make sure that no references to unavailable data can be made. This work is quite interesting in relation to the solution we propose in Section~\ref{sec:productivity}, since it also tries to discard unsafe data by using a notion of time. In contrast to Krishnaswami's approach which requires specific run-time behaviour in order to avoid ``space leaks'' (a specific type of memory leak, essentially), our proposal employs only static analysis. Nonetheless, the potential presence of memory leaks will have to be taken into account in our planned implementation of copatterns in Idris.

