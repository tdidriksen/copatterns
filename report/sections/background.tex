%!TEX root = ../main.tex
\section{Background}
\label{sec:background}

In the following, we explain the fundamental concepts underlying the remaining sections. These concepts include totality in general and productivity in particular, coinductive data, and copatterns.

\subsection{Why Do We Care About Totality?}
In a partial (i.e. non-total) programming setting, a well-typed program results in a value \emph{if} it terminates \emph{and} it does not result in a run-time error, both of which are possible (even for well-typed programs). Non-termination and run-time errors can be eliminated by making a program total.

\emph{Totality} means that for any input, the program always produces an output\,\citep{Turner04totalfunctional}. Consequently, any total program must be defined for all possible cases of its input. Otherwise, some input would exist for which no output would be defined. Stating that a program is total has different implications, depending on whether the output of a program is of inductive or coinductive type.

If a program results in an instance of an inductive type, it is total if it is \emph{terminating}. Since the output is finite by definition, a program is terminating when it has constructed all of its output. Termination is often ensured by showing that all recursive invocations of the program happens on structurally smaller input.

In the case where a program results in a coinductive instance, it is total if it is \emph{productive}. Because coinductive data is potentially infinite, the program cannot be expected to produce all of its output in finite time. Instead, a productive program must continuously be able to produce a finite prefix of its output in finite time. Hence, a total program returning something of coinductive type is said to be productive, since it must be able to produce an output on every invocation.

Making programs total has multiple benefits. First of all, it gives us a guarantee that an output is always produced. Secondly, due to the Curry-Howard correspondence, total programs can be used as proofs, which enables us to establish strong guarantees about program correctness. In Idris, partial functions are not evaluated by the type checker and thus can never consitute part of a proof. The reason for this is not only that the type checker may loop forever, but also because generally recursive functions give rise to an inconsistent logic. A common argument against total programming is that it is impossible to create programs which are not meant to terminate, such as servers and operating systems. But \emph{totality} should not be mistaken for \emph{termination}. It is true that servers and operating systems are not meant to terminate, but they can be productive, a notion which is well-suited for systems that need to be responsive. In short, we care about totality because it provides us with a guarantee that our programs always produce an output, which in addition to eliminating a whole class of errors ultimately enables us construct provably correct programs.

% Non-termination is a possibility
% Not used in proof --- not expanded by type checker
% We can write total servers and operating systems!
% termination vs. productivity

\subsection{Codata}
\label{sec:codata}
Coinductive data, or codata (these terms will be used interchangeably), is data defined in terms of \emph{observations}\,\citep{Jacobs97atutorial}. Since its inception, codata has proven to be a useful tool to describe dynamic structures involving some notion of state, such as transition systems and automata\,\citep{Jacobs97atutorial}, and informally we can say that it allows us to model infinite structures. The idea of infinity arises from the fact that we can define codata which can be observed in infinitely many different states.

\subsubsection{The Duality Between Inductive and Coinductive Data} There is a close correlation between inductively defined data and coinductively defined data. In the field of category theory, this correlation is often defined as the duality between initial algebra and final coalgebra\,\citep{Jacobs97atutorial}. For those less acquainted with category theory (which includes the authors), this duality can be described as the distinction between \emph{construction} and \emph{observation}. Inductive data is constructed by the application of a finite set of constructors, whereas coinductive data can be observed in a given state by a finite set of observations. The distinction is perhaps most easily made clear with an example. Consider a the list data structure in Figure~\ref{fig:inductive_list}, defined in Idris-like syntax:

\begin{figure}
\begin{alltt}
data List : Type -> Type where
  Nil  : List a 
  (::) : a  -> List a -> List a
\end{alltt}
\caption{An inductive definition of a list structure.}
\label{fig:inductive_list}
\end{figure}

An instance of \texttt{List} can be constructed using the two constructors, \texttt{Nil} and \texttt{(::)} (cons). Notably, the only way to construct a \texttt{List} in finite time is to apply the \texttt{Nil} constructor at some point. Hence, a \texttt{List} instance is clearly defined by construction, so \texttt{List} is an inductive definition. Could we define lists coinductively also? A coinductive definition requires that we define what can be observed about a list. So, what can we say about list? The definition of \texttt{List} provides some intuition. At any point in time, we can either observe no elements (\texttt{Nil}) or we can observe an element and the rest of the list (\texttt{(::)}). We cannot, however, straightforwardly implement a coinductive list with two such observations, since the observations in a coinductive definition must specify those observations which can be made at any \emph{one} point in time. Surely, we can never at the same time observe no elements and one element (and the rest of the list). What we can say is that if we blindly observe any position in the list, we will either find nothing, or we will find an element and a pointer to the rest of the list. Let us try to formalize this notion with the definition of \texttt{CoList} in Figure~\ref{fig:CoList}.

\begin{figure}
\begin{alltt}
codata CoList : Type -> Type where
  Elem : CoList a -> Either () (a, CoList a)
\end{alltt}
\caption{A coinductive definition of a list structure.}
\label{fig:CoList}
\end{figure}

% cons : a -> List a -> List a
% Elem (cons a l) = Just (a, l)

% append : List a -> List a -> List a
% Elem (append xs ys) = case Elem xs of
%                         Just (a, l) => Just (a, (append l ys))
%                         Nothing => Elem ys 

Notice how the types (and names) have changed. Since we have to define the object of our observations, the \texttt{Elem} observation must take a \texttt{CoList a} as parameter. Also, because we are not \emph{constructing} a \texttt{CoList}, the result of \texttt{Elem} does not have to be \texttt{CoList~a}. Instead it is an \texttt{Either} type, which denotes that whenever we try to observe an instance of \texttt{CoList}, we can either get nothing if the list is empty, represented here by a unit value, or \texttt{(x, xs)}, where \texttt{x} is an element and \texttt{xs} is the rest of the list. 

Understanding the duality between these two definitions requires a bit of desugaring. We can desugar the \texttt{Either} type from the second example into a sum type, \texttt{() + (a, CoList a)}. Furthermore, we can desugar the two constructors from the first example into one constructor. Since \texttt{Nil} has no parameters, its input can be described by a unit value. The \texttt{(::)} constructor has two parameters, an element and a list. The constructors of \texttt{List} can therefore be reduced to one constructor with a sum type \texttt{() + (a, List a)} as parameter, describing the input of both \texttt{Nil} and \texttt{(::)}. The desugared types of the two definitions are shown side by side in Figure~\ref{fig:List_CoList_duality}.

\begin{figure}
\begin{alltt}
List   : () + (a, List a)   ->   List a
CoList : CoList a           ->   () + (a, CoList a)
\end{alltt}
\caption{The desugared types of \texttt{List} and \texttt{CoList}.}
\label{fig:List_CoList_duality}
\end{figure}

When juxtaposing these types, it becomes apparent that the ways we can construct an inductively defined list is dual to what we can observe about a coinductively defined list. This duality is a general property which exists between inductive and coinductive data: Constructors tell us how data can be built, observations tell us what we can observe about our data.

% \subsubsection{Bisimulation}
% Since coinductive data has no inherent structure, it does not always make sense to talk about equality between two instances of a coinductive type. Instead, it may be the case that two instances of codata give rise to the same sequence of observations, such that they cannot be told apart by the results of our observations. When instances of codata are observationally indistinguishable in this way, we say they are \emph{bisimilar}, as one instance simulates the behaviour of the other. Further details on this phenomenon can be found in the tutorial by Jacobs and Rutten\,\citep{Jacobs97atutorial}.

\subsection{The Current Status of Codata in Idris}
\label{sec:stateinidris}
Coinductive data types already exist in Idris, although they are not defined by observations. Instead, they are defined by constructors. A coinductive definition by constructors as currently implemented in Idris is shown in Figure~\ref{fig:stream_current} for an infinite list, also called a \texttt{Stream}.

\begin{figure}
\begin{alltt}
codata Stream : Type -> Type where
  (::) : a -> Stream a -> Stream a
\end{alltt}
\caption{A stream definition as it currently looks in Idris.}
\label{fig:stream_current}
\end{figure}

At first glance, the type of the \texttt{(::)} constructor looks reasonable. Taking this type at face value, let us try to imagine how a \texttt{Stream} of all the natural numbers could be built:

\begin{alltt}
(0 :: (1 :: (2 :: (3 :: (4 :: (5 :: \ldots))))))
\end{alltt}

This seems to be impossible. Building a \texttt{Stream} requires a new \texttt{Stream}, which again requires a new \texttt{Stream}, leading to an infinite chain of \texttt{Stream}s. Is \texttt{Stream} inhabited at all? Fortunately, the answer is yes, the reason being that the syntax hides an important detail. Internally, the \texttt{(::)} constructor only requires a lazily evaluated \texttt{Stream} as its second argument. Instead of giving an actual stream, we can provide a promise that the rest of the \texttt{Stream} can be generated later. This is captured by the \texttt{Inf} type operator in Figure \ref{fig:stream_current_Inf_and_natsFrom}, which is applied automatically by elaborator. The corecursive call in \texttt{nats} will be lazily evaluated, and therefore not cause an infinite computation.

\begin{figure}
\begin{alltt}
codata Stream : Type -> Type where
  (::) : a -> Inf (Stream a) -> Stream a

natsFrom : Nat -> Stream Nat
natsFrom n = n :: Delay (natsFrom (S n))
\end{alltt}
\caption{A stream definition as it currently looks in Idris with the implicit \texttt{Inf} operator made explicit. This allows us to define an infinite sequence of natural numbers as shown with \texttt{natsFrom}. The \texttt{Delay} constructor for lazily evaluated defintions is applied on the recursive call to \texttt{natsFrom}.}
\label{fig:stream_current_Inf_and_natsFrom}
\end{figure}

This scheme of lazily evaluating coinductive arguments is applied automatically to any constructor in a \texttt{codata} declaration during elaboration, and \texttt{Inf} is therefore optional (for mixed inductive-coinductive definitions) in the concrete Idris syntax. As such, codata in Idris is currently modeled as lazily evaluated data where observations can be made by pattern matching.

To ensure the productivity of functions returning codata, Idris has a productivity checker which analyzes a program according to the \emph{guardedness} principle\,\citep{Coquand94,Gimenez95}: Any corecursive call must appear directly under a constructor. In the \texttt{natsFrom} example, the corecursive call appears directly under the \texttt{(::)} constructor. If we try to define the a stream of the natural numbers without a \texttt{Nat} argument (shown in Figure \ref{fig:nats}), however, the productivity checker rejects the program (as of Idris version \texttt{0.9.12-git:d9a96d1}, at least), complaining that \texttt{nats} is possibly not total. In this case the corecursive call does not appear directly under \texttt{(::)}, but is wrapped in a call to \texttt{map}. Therefore, even though \texttt{nats} is in fact productive, it is not productive according to the guardedness principle.

\begin{figure}
\begin{alltt}
nats : Stream Nat
nats = Z :: map S nats
\end{alltt}
\caption{A stream of all the natural numbers which is productive, but not according to the guardedness principle.}
\label{fig:nats}
\end{figure}

In its original formulation (which is also the one implemented for Idris), the guardedness principle is quite simple, but also rather conservative. The productivity checking algorithm we present in Section~\ref{sec:productivity} accepts more functions as being productive, but is arguably not as simple.

\subsection{Copatterns}
\label{sec:copatterns}
\emph{Destructor copatterns}, or simply \emph{copatterns}\,\citep{Abel13Copatterns}, provide a way of defining functions on coinductive data in terms of observations. Like pattern matching allows us to define functions on inductive data by analyzing the structure of the input, copatterns enable us to make experiments on functions with a result of coinductive type. Building on the intuition presented in Section~\ref{sec:codata}, we begin by defining an infinite list by observations, \texttt{Stream}, in the same vein as \texttt{CoList}:

\begin{figure}
\begin{alltt}
codata Stream : Type -> Type where
  head : Stream a -> a
  tail : Stream a -> Stream a 
\end{alltt}
\caption{An infinite list defined by observations.}
\label{fig:stream}
\end{figure}

The syntax for \texttt{codata} definitions presented in Figure~\ref{fig:stream} is quite similar to the existing syntax shown in Figure~\ref{fig:stream_current}. The major difference is that we no longer define constructors, but observations. On a \texttt{Stream}, two observations can be made: \texttt{head} and \texttt{tail}. The former provides us with the first element of the stream, while the latter gives us with the rest of the infinite stream, upon which another element can be observed with \texttt{head}. With respect to the stream definition given in Section~\ref{sec:stateinidris}, the \texttt{head} observation from Figure~\ref{fig:stream} corresponds to the first argument of the \texttt{(::)} constructor, and \texttt{tail} corresponds to the second argument. The \texttt{Stream} defined by observations can be used to define the \texttt{nats} function from Figure~\ref{fig:nats} using copatterns, as shown in Figure~\ref{fig:nats_copatterns}.

\begin{figure}
\begin{alltt}
nats : Stream Nat
head nats = Z
tail nats = map S nats
\end{alltt}
\caption{A definition of \texttt{nats} using copatterns.}
\label{fig:nats_copatterns}
\end{figure}

Because the result type of \texttt{nats} is coinductive, we can use copatterns to define the outcomes of our observations. The intuition is that the first element of \texttt{nats} is zero (\texttt{Z}), and the rest of the natural numbers are all the natural numbers incremented by one (\texttt{map S nats}). Initially, the \texttt{head} observation will therefore return \texttt{Z}. Making a \texttt{tail} observation results in a new stream where all the elements of \texttt{nats} are incremented by one (using the \texttt{S} constructor for natural numbers). Consequently, the outcome of making a subsequent \texttt{head} observation is \texttt{S Z}. As we can increment a natural number infinitely many times, we can also make infinitely many \texttt{tail} observations, where the result of a \texttt{head} observation will be incremented for each \texttt{tail} observation. 

Syntactically, projection happens on the outside of definitions when we use copatterns, as opposed to pattern matching, where projection on parameters happens inside of definitions. As an example, consider the definition of \texttt{map} in Figure~\ref{fig:map_copatterns}.

\begin{figure}
\begin{alltt}
map : (a -> b) -> Stream a -> Stream b
head (map f s) = f (head s)
tail (map f s) = map f (tail s)
\end{alltt}
\caption{The \texttt{map} function defined with copatterns.}
\label{fig:map_copatterns}
\end{figure}

For \texttt{map}, it is clear that the observations are applied on the entire definition \texttt{map f s}. Projections on the entire definition make sense because \texttt{map f s} has the coinductive type \texttt{Stream b}, and can therefore be the subject of observations. In this sense, copatterns can be said to be dual to pattern matching in the same way that coinductive data is dual to inductive data. With pattern matching, we can analyze how data has been constructed, and with copatterns we can define the outcome of observations. Where pattern matching is a way of processing input, copatterns provide the means for describing output. In continuation of this description, the behaviour of copatterns during evaluation becomes interesting, but we will defer this discussion to Section~\ref{sec:implementing-copatterns}.

In general, copatterns are used whenever we define a function that results in something coinductive. Nevertheless, there are some cases where definitions do not benefit from the use of copatterns, even though their result is coinductive. Especially, this is the case for definitions that are terminating rather than productive. An elaboration on this will be provided in Section~\ref{sec:copattern_in_idris_productivity_checker}.

% Dual to pattern matching

% Copatterns in Agda

% Inductively defined data can be analyzed by defining functions on that data by traditional pattern matching, where a \emph{pattern} is a (finite and valid) combination of constructor applications for the given data. In this respect, 

% \begin{figure}
% \begin{alltt}
% pow2 : Stream Nat
% head pow2 = S Z
% head (tail pow2) = S (S Z)
% tail (tail pow2) = zipWith _+_ (tail pow2) (tail pow2)
% \end{alltt}
% \caption{A definition of an infinite stream of powers of 2 using copatterns.}
% \end{figure}

% by defining functions on that data using traditional pattern 

% Inductively defined data can be analyzed by defining functions in terms of a set of \textit{patterns}, where a pattern constitutes a recognizable structure in the data we are analyzing. 




% Because we know that the data has been constructed using a finite number of data constructors, the number of ways we can take that same data apart is also finite by definition. 


% Consider a standard list data structure, defined in Haskell-like syntax:

% \begin{alltt}
% data List a = Nil 
%             | Cons a (List a)
% \end{alltt}

% \texttt{List a} consists of two data constructors, \texttt{Nil} and \texttt{Cons}. Because these two constructors constitute the only that we can construct a \texttt{List a}, 

\subsection{Existing Implementations of Copatterns}
Copatterns already exist in other languages, for example in Agda\,\cite{Norell:thesis}. Here, definitions for coinductive types are quite interesting. A coinductive type is defined as a record type with a \texttt{coinductive} flag, an example of which can be seen in Figure~\ref{fig:agda_stream}. Observations are defined as fields of the record type.

%Notice the implicit sizes. These are not strictly necessary, but are needed if the user wants productivity checking using sized types rather than guardedness. These different techniques for are discussed in Section~\ref{sec:related_work}. 

\begin{figure}
\begin{alltt}
record Stream (A : Set) : Set where
  coinductive
  field
    head : A
    tail : Stream A
open Stream
\end{alltt}
\caption{Sized \texttt{Stream} definition in Agda.}
\label{fig:agda_stream}
\end{figure}

Definitions with copatterns are almost identical to what has already been discussed. A simple example where sized types are not necessary for productivity checking is \texttt{repeat} in Figure~\ref{fig:agda_repeat}. This definition passes a simple guardedness check.

\begin{figure}
\begin{alltt}
repeat : \{A : Set\} -> A -> Stream A
head (repeat a) = a
tail (repeat a) = repeat a 
\end{alltt}
\caption{A corecursive \texttt{repeat} function in Agda.}
\label{fig:agda_repeat}
\end{figure}

If we want to write more advanced corecursive functions in Agda, we have to use sized types to reason about productivity. Further discussion on these will be provided in Section~\ref{sec:sized_types}.

%Earlier we saw a definition of a stream of natural numbers. An Agda implementation of this is shown in Figure~\ref{fig:agda_nats}. Since \texttt{nats} does not pass the guardedness check, we have to help the productivity checker by using sized types.